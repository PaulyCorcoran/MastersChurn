{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyspark.ml.classification import  DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import timeit\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "import os\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import math\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from random import random\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = 'C:/Program Files/Java/jre1.8.0_333/'\n",
    "os.environ[\"SPARK_HOME\"] = 'C:/spark/spark-3.3.0-bin-hadoop2/'\n",
    "os.environ[\"HADOOP_HOME\"] = 'C:/hadoop/'\n",
    "#os.environ[\"PYSPARK_SUBMIT_ARGS\"] = '--master local pyspark-shell'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:/spark/spark-3.3.0-bin-hadoop2/'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.find()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "findspark.init()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    ".builder\\\n",
    ".master(\"local\")\\\n",
    ".config(\"spark.executor.cores\", \"4\")\\\n",
    ".config(\"spark.executor.memory\", \"10g\")\\\n",
    ".config(\"spark.driver.memory\", \"10g\")\\\n",
    ".config(\"spark.executor.memoryOverhead\", \"10g\")\\\n",
    ".appName(\"Churn Project\").getOrCreate()\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "df = spark.read.csv('C:/Users/paulc/Documents/Data Analysis Courses/MastersChurn/ProjectWork/ChurnModelScaled.csv',inferSchema=True,header=True)\n",
    "scaled_df = spark.read.csv('C:/Users/paulc/Documents/Data Analysis Courses/MastersChurn/ProjectWork/ChurnModelScaled.csv',inferSchema=True,header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "df = df.drop('_c0')\n",
    "scaled_df = scaled_df.drop('_c0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "numericCols = ['MonthNumber', 'ClientProfileSummary', 'Gender', 'CashActive_YN',\n",
    "       'L1DSBBetCount', 'L7DSBBetCount', 'L30DSBBetCount', 'L90DSBBetCount',\n",
    "       'L1DDepositCount', 'L7DDepositCount', 'L30DDepositCount',\n",
    "       'L90DDepositCount', 'L7DOtherSportsBetCount', 'L30DOtherSportsBetCount',\n",
    "       'L90DOtherSportsBetCount', 'L90DUnsuccessfulDepositCount',\n",
    "       'DaysSinceLastSBCashAPD', 'DaysSinceLastSBAPD', 'OlderMale40',\n",
    "       'CustomerConcession90days',\n",
    "       'L7DSBTurnover', 'US_SportsTurnover7D', 'L30DSBTurnover',\n",
    "       'US_SportsTurnover30D', 'CustomerConcession30days', 'L90DSBTurnover',\n",
    "       'L1DSBTurnover', 'US_SportsTurnover1D', 'L30DSBFreeBetsHandle',\n",
    "       'US_SportsTurnover90D', 'L7DSBFreeBetsHandle']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "scaled_df = assembler.transform(scaled_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train/Test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "train,test = df.randomSplit([0.7,0.3],seed=42)\n",
    "train_scaled,test_scaled = scaled_df.randomSplit([0.7,0.3],seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Single Decision Tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.1719\n",
      "Accuracy of Model = 0.8281\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"Active_Next30Days_Cash_YN\",featuresCol=\"features\")\n",
    "\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = dt.fit(train_scaled)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(test_scaled)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"Active_Next30Days_Cash_YN\", \"features\")\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Active_Next30Days_Cash_YN\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print (\"Test Error = %g\" % round(1.0 - accuracy,4))\n",
    "print (\"Accuracy of Model = %g\" % round(accuracy,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Naive Bayes Classifers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.7635204064623242\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(labelCol='Active_Next30Days_Cash_YN',featuresCol='features', modelType=\"gaussian\",smoothing=1.0)\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train_scaled)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test_scaled)\n",
    "#predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Active_Next30Days_Cash_YN\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.751511898491102\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(labelCol='Active_Next30Days_Cash_YN',featuresCol='features', modelType=\"complement\",smoothing=1.0)\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train_scaled)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test_scaled)\n",
    "#predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Active_Next30Days_Cash_YN\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.7503117144628844\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(labelCol='Active_Next30Days_Cash_YN',featuresCol='features', modelType=\"multinomial\",smoothing=1.0)\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train_scaled)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test_scaled)\n",
    "#predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Active_Next30Days_Cash_YN\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###################################################################################################################################\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Support Vector Machine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.13185678870753856,0.7589561392486014,0.1224468449946559,1.4615638831327482,-7.572733217473998,69.01882415541422,37.73086335708482,12.98736916342468,-17.331924827905404,16.5415200181224,4.105495676697325,7.880711656800446,38.1921952954533,29.057281513310446,26.062265121802625,-7.441674941188936,-1.789883321514026,-1.2965821055643578,0.08582183953130032,-0.034138110532546714,10.272750266253393,13.340589266271667,6.07614326394855,12.9168374776068,0.13951346070113327,-0.926492741160736,-7.432986498798965,1.448829957355958,-21.121447610192547,3.7112371017138526,46.279263953732666]\n",
      "Intercept: -1.2014786089400225\n",
      "Test set accuracy = 0.7933383118744874\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "lsvc = LinearSVC(labelCol='Active_Next30Days_Cash_YN',featuresCol='features',maxIter=300,aggregationDepth=50, regParam=0.01)\n",
    "\n",
    "# Fit the model\n",
    "lsvcModel = lsvc.fit(train_scaled)\n",
    "\n",
    "# Print the coefficients and intercept for linear SVC\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))\n",
    "\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = lsvcModel.transform(test)\n",
    "#predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Active_Next30Days_Cash_YN\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}