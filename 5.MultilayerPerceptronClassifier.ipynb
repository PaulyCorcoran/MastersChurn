{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import timeit\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "import os\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import math\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from random import random\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = 'C:/Program Files/Java/jre1.8.0_333/'\n",
    "os.environ[\"SPARK_HOME\"] = 'C:/spark/spark-3.3.0-bin-hadoop2/'\n",
    "os.environ[\"HADOOP_HOME\"] = 'C:/hadoop/'\n",
    "#os.environ[\"PYSPARK_SUBMIT_ARGS\"] = '--master local pyspark-shell'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:/spark/spark-3.3.0-bin-hadoop2/'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.find()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "findspark.init()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    ".builder\\\n",
    ".master(\"local\")\\\n",
    ".config(\"spark.executor.cores\", \"4\")\\\n",
    ".config(\"spark.executor.memory\", \"10g\")\\\n",
    ".config(\"spark.driver.memory\", \"10g\")\\\n",
    ".config(\"spark.executor.memoryOverhead\", \"10g\")\\\n",
    ".appName(\"Churn Project\").getOrCreate()\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = spark.read.csv('C:/Users/paulc/Documents/Data Analysis Courses/MastersChurn/ProjectWork/ChurnModelScaled.csv',inferSchema=True,header=True)\n",
    "scaled_df = spark.read.csv('C:/Users/paulc/Documents/Data Analysis Courses/MastersChurn/ProjectWork/ChurnModelScaled.csv',inferSchema=True,header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df = df.drop('_c0')\n",
    "scaled_df = scaled_df.drop('_c0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "numericCols = ['MonthNumber', 'ClientProfileSummary', 'Gender', 'CashActive_YN',\n",
    "       'L1DSBBetCount', 'L7DSBBetCount', 'L30DSBBetCount', 'L90DSBBetCount',\n",
    "       'L1DDepositCount', 'L7DDepositCount', 'L30DDepositCount',\n",
    "       'L90DDepositCount', 'L7DOtherSportsBetCount', 'L30DOtherSportsBetCount',\n",
    "       'L90DOtherSportsBetCount', 'L90DUnsuccessfulDepositCount',\n",
    "       'DaysSinceLastSBCashAPD', 'DaysSinceLastSBAPD', 'OlderMale40',\n",
    "       'CustomerConcession90days',\n",
    "       'L7DSBTurnover', 'US_SportsTurnover7D', 'L30DSBTurnover',\n",
    "       'US_SportsTurnover30D', 'CustomerConcession30days', 'L90DSBTurnover',\n",
    "       'L1DSBTurnover', 'US_SportsTurnover1D', 'L30DSBFreeBetsHandle',\n",
    "       'US_SportsTurnover90D', 'L7DSBFreeBetsHandle']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "scaled_df = assembler.transform(scaled_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train/Test Split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train,test = df.randomSplit([0.7,0.3],seed=42)\n",
    "train_scaled,test_scaled = scaled_df.randomSplit([0.7,0.3],seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['MonthNumber',\n 'ClientProfileSummary',\n 'Gender',\n 'CashActive_YN',\n 'L1DSBBetCount',\n 'L7DSBBetCount',\n 'L30DSBBetCount',\n 'L90DSBBetCount',\n 'L1DDepositCount',\n 'L7DDepositCount',\n 'L30DDepositCount',\n 'L90DDepositCount',\n 'L7DOtherSportsBetCount',\n 'L30DOtherSportsBetCount',\n 'L90DOtherSportsBetCount',\n 'L90DUnsuccessfulDepositCount',\n 'DaysSinceLastSBCashAPD',\n 'DaysSinceLastSBAPD',\n 'OlderMale40',\n 'CustomerConcession90days',\n 'Active_Next30Days_Cash_YN',\n 'L7DSBTurnover',\n 'US_SportsTurnover7D',\n 'L30DSBTurnover',\n 'US_SportsTurnover30D',\n 'CustomerConcession30days',\n 'L90DSBTurnover',\n 'L1DSBTurnover',\n 'US_SportsTurnover1D',\n 'L30DSBFreeBetsHandle',\n 'US_SportsTurnover90D',\n 'L7DSBFreeBetsHandle',\n 'features']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the MLPC is: 0.5274\n"
     ]
    }
   ],
   "source": [
    "# layers 31 is the number of features, 16 is the only layer and 2 is the output layer\n",
    "\n",
    "mlpc=MultilayerPerceptronClassifier(featuresCol='features',labelCol='Active_Next30Days_Cash_YN',layers = [31,16,2],maxIter=10,blockSize=128,seed=42,solver='gd')\n",
    "ann = mlpc.fit(scaled_df)\n",
    "\n",
    "pred = ann.transform(test_scaled)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Active_Next30Days_Cash_YN',predictionCol='prediction',metricName='f1')\n",
    "ann_f1 = evaluator.evaluate(pred)\n",
    "print(\"The Accuracy of the MLPC is:\",round(ann_f1,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Increasing the number of layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the MLPC is: 0.5274\n"
     ]
    }
   ],
   "source": [
    "mlpc=MultilayerPerceptronClassifier(featuresCol='features',labelCol='Active_Next30Days_Cash_YN',layers = [31,128,64,16,8,4,2],maxIter=20,blockSize=128,seed=42,solver='gd')\n",
    "ann = mlpc.fit(scaled_df)\n",
    "\n",
    "pred = ann.transform(test_scaled)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Active_Next30Days_Cash_YN',predictionCol='prediction',metricName='f1')\n",
    "ann_f1 = evaluator.evaluate(pred)\n",
    "print(\"The Accuracy of the MLPC is:\",round(ann_f1,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the MLPC is: 0.7506\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 8min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlpc=MultilayerPerceptronClassifier(featuresCol='features',labelCol='Active_Next30Days_Cash_YN',layers = [31,128,64,16,8,4,2],maxIter=20,blockSize=128,seed=42,solver='l-bfgs')\n",
    "ann = mlpc.fit(scaled_df)\n",
    "\n",
    "pred = ann.transform(test_scaled)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Active_Next30Days_Cash_YN',predictionCol='prediction',metricName='f1')\n",
    "ann_f1 = evaluator.evaluate(pred)\n",
    "print(\"The Accuracy of the MLPC is:\",round(ann_f1,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the MLPC is: 0.7924\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 45min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlpc=MultilayerPerceptronClassifier(featuresCol='features',labelCol='Active_Next30Days_Cash_YN',layers = [31,128,64,16,8,4,2],maxIter=50,blockSize=128,seed=42,solver='l-bfgs')\n",
    "ann = mlpc.fit(scaled_df)\n",
    "\n",
    "pred = ann.transform(test_scaled)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Active_Next30Days_Cash_YN',predictionCol='prediction',metricName='f1')\n",
    "ann_f1 = evaluator.evaluate(pred)\n",
    "print(\"The Accuracy of the MLPC is:\",round(ann_f1,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# layers 31 is the number of features, 16 is the only layer and 2 is the output layer\n",
    "\n",
    "mlpc=MultilayerPerceptronClassifier(featuresCol='features',labelCol='Active_Next30Days_Cash_YN',layers = [31,128,64,16,8,4,2],maxIter=200,blockSize=128,seed=42,solver='l-bfgs')\n",
    "ann = mlpc.fit(scaled_df)\n",
    "\n",
    "pred = ann.transform(test_scaled)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Active_Next30Days_Cash_YN',predictionCol='prediction',metricName='f1')\n",
    "ann_f1 = evaluator.evaluate(pred)\n",
    "print(\"The Accuracy of the MLPC is:\",round(ann_f1,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}